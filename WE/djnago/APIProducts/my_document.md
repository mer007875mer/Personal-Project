# Upstream and Downstream cache:
  
    -Upstream Cache:

        -Location: Upstream cache is situated closer to the client, usually within the reverse proxy server.
        -Purpose: It stores and serves cached content to clients directly, reducing the load on backend servers and improving response times.
        -Content: Typically caches static assets, such as images, stylesheets, and JavaScript files.
        -Management: Managed by the reverse proxy server, which decides what content to cache and for how long.
        -Benefits: Reduces server load, improves user experience, saves bandwidth, and enhances content delivery.
        -Use Cases: Suitable for caching frequently accessed static content, which remains relatively unchanged over time.

    -Downstream Cache:

        -Location: Downstream cache is located closer to the backend servers, within the server hosting the application or the application framework itself.
        -Purpose: It caches frequently used data or responses generated by backend services to improve application performance.
        -Content: Caches dynamic data, API responses, database queries, and other server-generated content.
        -Management: Managed by the application code, which determines what data to cache and when to invalidate the cache.
        -Benefits: Reduces database queries, improves response times, and optimizes application performance.
        -Use Cases: Suitable for caching dynamic content, database query results, API responses, and computations to reduce the workload on backend services.


# Start a new server:

    Create and Edit Configuration File:
        cp /etc/redis/redis.conf /etc/redis/redis6380.conf
        nano /etc/redis/redis6380.conf
        change the port from -> port 6379 to port 6380
    
    Start the Redis Server:
        redis-server /etc/redis/redis6380.conf
    
    Restart the Redis Server:
        sudo systemctl restart redis
    
    Verify the Server:
        ps aux | grep redis
        
    Connect Using redis-cli:
        redis-cli -h 127.0.0.1 -p 6380
        

# Apply the Saving 

    Snapshotting(RDB):
        nano /etc/redis/redis6380.conf
        save <second> <changes>
        restart redis
        
        Other Persistence Options:
               rdbcompression yes/no :Compress RDB snapshot files
               rdbchecksum yes/no :Add CRC64 checksum to RDB snapshot files for data integrity checking
               dir /var/redis/data/ :Specify the directory where RDB and AOF files are saved
               dbfilename dump.rdb :Specify the filename for the RDB snapshot
               appendfilename "appendonly.aof" :Specify the filename for the AOF log
               aof-rewrite-incremental-fsync yes/no :Enable incremental fsync during AOF rewrite for better fsync efficiency.
        
    Append-Only File:
        nano /etc/redis/redis.conf
        appendonly no -> appendonly yes
        
        Configure when AOF data is synced to disk:
            appendfsync always :Every write operation is immediately synced to disk. Highest durability, slowest performance.
            appendfsync everysec :Data is buffered and synced to disk every second. Good balance between durability and performance.
            appendfsync no :Data is buffered but not synced to disk, relying on OS to flush changes. Good performance, lowest durability.
        
        Configure the frequency of AOF rewrites:
            add following line 
            auto-aof-rewrite-percentage 100 :rewrite the AOF file when is 100% of the size of the current data set
            auto-aof-rewrite-min-size 64mb :rewrite the AOF file when the size is larger than 64mb
        
        Restart redis server
            
    
    AOF vs RDB:
        -Data Durability: 
        If data durability and minimal data loss are critical, AOF is a better choice. The always or everysec persistence modes ensure that data is written to disk frequently.
        
        -Performance: 
        If write performance is crucial and you can tolerate the risk of occasional data loss, RDB snapshotting may be more suitable.
        
        -Disk Space Usage: 
        If disk space is a concern, AOF with periodic rewriting can help optimize space usage, but it's essential to monitor and manage the process.
        

# Common operations: 
    
    Strings:
        SET key value: Set the value of a key.
        SET key value NX : set a key only if it doesn't exist
        GET key: Get the value of a key.
        INCR key: Increment the value of a key (assumes the value is an integer).
        APPEND key value: Append a value to an existing string.
        
    Lists:
        LPUSH key value: Push a value onto the front of a list.
        RPUSH key value: Push a value onto the end of a list.
        LPOP key: Pop a value from the front of a list.
        RPOP key: Pop a value from the end of a list.
        LRANGE key start end: Get a range of elements from a list.
        
    Sets:
        SADD key member: Add a member to a set.
        SREM key member: Remove a member from a set.
        SMEMBERS key: Get all members of a set.
        SISMEMBER key member: Check if a member exists in a set.
        
    Key Management:
        DEL key [key ...]: Delete one or more keys.
        EXISTS key: Check if a key exists.
        RENAME oldkey newkey: Rename a key.
        KEYS pattern: Retrieve keys matching a pattern.
        
    Data Manipulation:
        GETSET key value: Set a value and return its old value atomically.
        INCRBY key increment: Increment a key's value by a specified amount.
        DECRBY key decrement: Decrement a key's value by a specified amount.
        STRLEN key: Get the length of a string value.
        
    Expire Management:
        EXPIRE key seconds: Setting Expiration 
        TTL key: Getting Remaining Time
        Deleting Keys: DEL key [key ...]
        PERSIST key: Removing Expiration
        SETEX key seconds value: Setting Expiration on Creation
        
        
    Transaction:
        MULTI: 
        Start a transaction using the MULTI command. After this command, Redis will queue all subsequent commands to be executed atomically.

        Queue Your Commands:
        Queue the Redis commands you want to execute as part of the transaction.

        EXEC:
        Execute the queued commands as a transaction using the EXEC command. If all commands succeed, they are executed atomically. If any command fails (e.g., due to a command-specific   error), the entire transaction is rolled back, and no changes are made to the database.

        DISCARD:
        If you decide not to execute the queued commands, you can discard the transaction using this command
        
        
        Sure, here's an example of a Redis transaction using the MULTI, EXEC, and DISCARD commands in a Python script:
        
        
# Master-Slave:
    
    -Master:
        The master instance is the primary Redis instance that stores the original dataset.
        It can handle both read and write operations.
        Any write operations performed on the master are propagated to the slave instances.
        
    -Slave:
        Slave instances are read-only replicas of the master instance.
        They mirror the data from the master and are primarily used for serving read operations.
        Slave instances don't accept write operations directly; they only receive data from the master and keep themselves synchronized.
        
    -setting up:
        On the master: Enable replication in the redis.conf file: slaveof no one
        On the slave: Configure replication in the redis.conf file: slaveof <master_ip> <master_port>
        restart redis server
        
        INFO replication : provides information about the master, connected slaves, replication lag, and more.
        
    -setting up in django cache (using django-redis-py-cluster libary):
        settings.py : 
        
        CACHES = {
            "default": {
                "BACKEND": "django_redis.cache.RedisCache",
                "LOCATION": "redis://localhost:7000,redis://localhost:7001,redis://localhost:7002",
            "OPTIONS": {
                "CLIENT_CLASS": "django_redis.client.ClusterClient",
                "READ_PREFERENCE": "slave",  # Read from slave nodes
                "WRITE_PREFERENCE": "master",  # Write to master node
                },
            }
               
       
        
        
# Setting up the cluster 

    Configure redis.conf: 
        master.conf:
            port 7000   
            cluster-enabled yes
            cluster-config-file nodes.conf
            cluster-node-timeout 5000
            appendonly yes
            
        replica.conf:
            port 7001
            cluster-enabled yes
            cluster-config-file nodes.conf
            cluster-node-timeout 5000
            appendonly yes
            replicaof 127.0.0.1 7000  # Master's IP and port
        
    Start redis server:
        redis-server /path/to/master.conf
        
    Create the Redis-Cluster:
        redis-cli --cluster create \
          127.0.0.1:7000 127.0.0.1:7001 \
          --cluster-replicas 1
          
    Verfy the Redis Cluster:
        redis-cli -c -p 7000 cluster nodes
        
    Install redis and configure setting.py:
    
        CACHES = {
        'default': {
            'BACKEND': 'django_redis.cache.RedisCache',
            'LOCATION': [
                "redis://redis_cluster_node_1:6379/1",  # Replace with your Redis Cluster nodes
                "redis://redis_cluster_node_2:6379/1",
                # Add more nodes here as needed
            ],
            'OPTIONS': {
                'CLIENT_CLASS': 'django_redis.client.DefaultClient',
                }
            }
        }
        


# Securing Redis instance
    
    Change Default Settings: 
        Change the default port (6379) to a different one to avoid easy identification by attackers.
        Configure Redis to bind to specific IP addresses to limit network exposure.

    Enable Authentication:
        Set a strong password using the requirepass configuration directive in your redis.conf file.
        in redis.conf add -> requirepass Your_Strong_Password_Here
        
    Role-Based Access Control:
        127.0.0.1:6379> ACL SETUSER username_here on >password_here +@all -@dangerous
            username_here is the name of the user
            password_here is the user's password
            +@all grants the user all available commands
            -@dangerous denies the user specific dangerous commands
    
    SSL/TLS:
        Generate SSL/TLS Certificates: openssl req -x509 -newkey rsa:4096 -keyout redis-key.pem -out redis-cert.pem -days 365
         Update Redis Configuration : add the following line in redis.conf
            # Enable SSL
            tls-port 6380
            tls-cert-file /path/to/redis-cert.pem
            tls-key-file /path/to/redis-key.pem
         Restart Redis
         
         update django setting.py
            CACHES = {
                'default': {
                    'BACKEND': 'django_redis.cache.RedisCache',
                    'LOCATION': 'rediss://your_redis_host:6380/1',  # Use 'rediss' for SSL
                    'OPTIONS': {
                        'CLIENT_CLASS': 'django_redis.client.DefaultClient',
                        'CONNECTION_POOL_KWARGS': {'ssl_certfile': '/path/to/redis-cert.pem'},
                    }
                }
            }

        

